{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dikshuy/jax-MAML/blob/main/maml_omniglot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x2PT6TsCS1z",
        "outputId": "7328b58f-43f2-473a-e580-0d51f1b721dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from optax) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from optax) (4.1.1)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.7+cuda11.cudnn805)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.8)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax) (0.1.3)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax) (1.1.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.7)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.11.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.4.1)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax) (2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install optax"
      ],
      "id": "1x2PT6TsCS1z"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0899ff72-046f-40f9-a72f-5ff311b78f32"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp              \n",
        "import optax                         \n",
        "import numpy as np                   \n",
        "import tensorflow_datasets as tfds    # TFDS for Omniglot\n",
        "import tensorflow as tf\n",
        "from jax import grad\n",
        "from jax import vmap \n",
        "from functools import partial\n",
        "from jax import jit \n",
        "from jax.experimental import stax \n",
        "from jax.experimental.stax import Conv, Dense, MaxPool, Relu, Flatten, Softmax, LogSoftmax, AvgPool, BatchNorm\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "from jax.experimental import optimizers\n",
        "from jax.tree_util import tree_multimap\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle"
      ],
      "id": "0899ff72-046f-40f9-a72f-5ff311b78f32"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_4apWHvPGjRL"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "rng, init_rng = jax.random.split(rng)"
      ],
      "id": "_4apWHvPGjRL"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GxggwO0UGo4D"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "meta_step_size = 0.001\n",
        "\n",
        "batch_size = 25\n",
        "\n",
        "meta_iters = 2000\n",
        "eval_iters = 5\n",
        "inner_iters = 4\n",
        "\n",
        "eval_interval = 1\n",
        "train_shots = 20\n",
        "shots = 5\n",
        "classes = 5"
      ],
      "id": "GxggwO0UGo4D"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_SYCLcSiHIow"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    # This class will facilitate the creation of a few-shot dataset\n",
        "    # from the Omniglot dataset that can be sampled from quickly while also\n",
        "    # allowing to create new labels at the same time.\n",
        "    def __init__(self, training):\n",
        "        # Download the tfrecord files containing the omniglot data and convert to a\n",
        "        # dataset.\n",
        "        split = \"train\" if training else \"test\"\n",
        "        ds = tfds.load(\"omniglot\", split=split, as_supervised=True, shuffle_files=False)\n",
        "        # Iterate over the dataset to get each individual image and its class,\n",
        "        # and put that data into a dictionary.\n",
        "        self.data = {}\n",
        "\n",
        "        def extraction(image, label):\n",
        "            # This function will shrink the Omniglot images to the desired size,\n",
        "            # scale pixel values and convert the RGB image to grayscale\n",
        "            image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "            image = tf.image.rgb_to_grayscale(image)\n",
        "            image = tf.image.resize(image, [28, 28])\n",
        "            return image, label\n",
        "\n",
        "        for image, label in ds.map(extraction):\n",
        "            image = image.numpy()\n",
        "            label = str(label.numpy())\n",
        "            if label not in self.data:\n",
        "                self.data[label] = []\n",
        "            self.data[label].append(image)\n",
        "        self.labels = list(self.data.keys())\n",
        "\n",
        "\n",
        "    def get_mini_dataset(\n",
        "        self, shots = shots, num_classes = classes\n",
        "    ):\n",
        "        temp_labels = np.zeros(shape=(num_classes * shots))\n",
        "        temp_images = np.zeros(shape=(num_classes * shots, 28, 28, 1))\n",
        "        test_labels = np.zeros(shape=(num_classes))\n",
        "        test_images = np.zeros(shape=(num_classes, 28, 28, 1))\n",
        "\n",
        "        # Get a random subset of labels from the entire label set.\n",
        "        label_subset = random.choices(self.labels, k=num_classes)\n",
        "        for class_idx, class_obj in enumerate(label_subset):\n",
        "            # Use enumerated index value as a temporary label for mini-batch in\n",
        "            # few shot learning.\n",
        "            temp_labels[class_idx * shots : (class_idx + 1) * shots] = class_idx\n",
        "            # label to create the test dataset.\n",
        "            test_labels[class_idx] = class_idx\n",
        "            images_to_split = random.choices(\n",
        "                self.data[label_subset[class_idx]], k=shots + 1\n",
        "            )\n",
        "            test_images[class_idx] = images_to_split[-1]\n",
        "            temp_images[\n",
        "                class_idx * shots : (class_idx + 1) * shots\n",
        "            ] = images_to_split[:-1]\n",
        "        \n",
        "        temp_images, temp_labels = shuffle(temp_images.astype(np.float32), temp_labels.astype(np.int32))\n",
        "        \n",
        "        support_set = {'images': temp_images, 'labels': temp_labels}\n",
        "        query_set = {'images': test_images, 'labels': test_labels}\n",
        "        \n",
        "        return support_set, query_set"
      ],
      "id": "_SYCLcSiHIow"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pfPyVU2aIHK1"
      },
      "outputs": [],
      "source": [
        "import urllib3\n",
        "\n",
        "urllib3.disable_warnings()  # Disable SSL warnings that may happen during download.\n",
        "train_dataset = Dataset(training=True)\n",
        "test_dataset = Dataset(training=False)"
      ],
      "id": "pfPyVU2aIHK1"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "W637JI6GGXRT"
      },
      "outputs": [],
      "source": [
        "net_init, net_apply = stax.serial(\n",
        "    Conv(out_chan = 64, filter_shape = (3,3), strides = [1,1], padding = 'SAME'), BatchNorm(), Relu,\n",
        "    Conv(out_chan = 64, filter_shape = (3,3), strides = [1,1], padding = 'SAME'), BatchNorm(), Relu,\n",
        "    Conv(out_chan = 64, filter_shape = (3,3), strides = [1,1], padding = 'SAME'), BatchNorm(), Relu,\n",
        "    Conv(out_chan = 64, filter_shape = (3,3), strides = [1,1], padding = 'SAME'), BatchNorm(), Relu,\n",
        "    AvgPool((28, 28)),\n",
        "    Flatten,\n",
        "    Dense(classes),\n",
        ")\n",
        "\n",
        "in_shape = (-1, 28, 28, 1)\n",
        "out_shape, net_params = net_init(rng, in_shape)"
      ],
      "id": "W637JI6GGXRT"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zsLK90gBIhZZ"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def loss(params, inputs, targets):\n",
        "    predictions = net_apply(params, inputs)\n",
        "    return jnp.mean(optax.softmax_cross_entropy(predictions, jax.nn.one_hot(targets, num_classes=classes)))"
      ],
      "id": "zsLK90gBIhZZ"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KFAPyHZNJVCA"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(logits, labels):\n",
        "    loss_ = np.mean(optax.softmax_cross_entropy(logits, jax.nn.one_hot(labels, num_classes=classes)))\n",
        "    accuracy = np.mean(np.argmax(logits, -1) == labels)\n",
        "    metrics = {\n",
        "      'loss': loss_,\n",
        "      'accuracy': accuracy\n",
        "    }\n",
        "    return metrics"
      ],
      "id": "KFAPyHZNJVCA"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "q3i-K0XdCYrR"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def inner_update(params, inputs, outputs, alpha = learning_rate):\n",
        "    '''\n",
        "    input:\n",
        "    - params: model's parameters\n",
        "    - inputs\n",
        "    - targets: true label\n",
        "    output\n",
        "    - updated parameters\n",
        "    '''\n",
        "    grads = grad(loss)(params, inputs, outputs)\n",
        "    grad_update_fn = lambda g, state: (state - alpha * g)\n",
        "    return tree_multimap(grad_update_fn, grads, params)"
      ],
      "id": "q3i-K0XdCYrR"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5c309d17-0207-4043-8944-2303732a1632"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def maml_loss(params, support_img, support_lab, query_img, query_lab, num_inner_loops=7):\n",
        "    '''\n",
        "    input:\n",
        "    - params: model's parameters\n",
        "    - x1, y1: task's train set\n",
        "    - x2, y2: task's test set\n",
        "    output:\n",
        "    - Loss after update parameters 1 time on the test set.\n",
        "    '''\n",
        "    params_updated = params\n",
        "    for _ in range(num_inner_loops):\n",
        "        params_updated = inner_update(params_updated, support_img, support_lab)\n",
        "    return loss(params_updated, query_img, query_lab)"
      ],
      "id": "5c309d17-0207-4043-8944-2303732a1632"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "OCkUhBqfAqTE"
      },
      "outputs": [],
      "source": [
        "import numpy as onp\n",
        "from jax.experimental import optimizers\n",
        "from jax.tree_util import tree_multimap "
      ],
      "id": "OCkUhBqfAqTE"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "S0jggTb569_j"
      },
      "outputs": [],
      "source": [
        "# Define optimizer\n",
        "opt_init, opt_update, get_params = optimizers.adam(step_size=meta_step_size)\n",
        "opt_state = opt_init(net_params)  "
      ],
      "id": "S0jggTb569_j"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "253bcb26-3a0a-45d3-8d95-845054db57bf"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "#Define a step (using jit to improve speed)\n",
        "@jit\n",
        "def step(i, opt_state, support_img, support_lab, query_img, query_lab):\n",
        "    '''\n",
        "    input:\n",
        "    - step number, opt_state (contains params)\n",
        "    -x1, y1: train, x2, y2: test and get loss\n",
        "    output:\n",
        "    - new opt_state and loss\n",
        "    '''\n",
        "    # Get params from opt_state\n",
        "    p = get_params(opt_state)\n",
        "    # calculate gradient from maml_loss\n",
        "    g = grad(maml_loss)(p, support_img, support_lab, query_img, query_lab)\n",
        "    # pre-model update trial on task.\n",
        "    l = maml_loss(p, support_img, support_lab, query_img, query_lab)\n",
        "    \n",
        "    return opt_update(i, g, opt_state), l"
      ],
      "id": "253bcb26-3a0a-45d3-8d95-845054db57bf"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "LGCLyOzG7MWk"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def maml_loss_batch(params, x1_b, y1_b, x2_b, y2_b):\n",
        "    '''\n",
        "    input:\n",
        "    - params\n",
        "    - x1_b, y1_b, x2_b, y2_b: batches of sample task \n",
        "    output:\n",
        "    - combined loss of the batch\n",
        "    '''\n",
        "    return onp.mean(vmap(partial(maml_loss, params))(x1_b, y1_b, x2_b, y2_b))"
      ],
      "id": "LGCLyOzG7MWk"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "JtupoDBb7SwH"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def batch_step(i, opt_state, x1_b, y1_b, x2_b, y2_b):\n",
        "    p = get_params(opt_state)\n",
        "    g = grad(maml_loss_batch)(p, x1_b, y1_b, x2_b, y2_b)\n",
        "    l = maml_loss_batch(p, x1_b, y1_b, x2_b, y2_b)\n",
        "    return opt_update(i, g, opt_state), l"
      ],
      "id": "JtupoDBb7SwH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e88d7be6-e143-492a-b05d-1908246d94d9",
        "outputId": "882f0a33-379d-4730-92b4-647e9c5f0274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/jax/_src/tree_util.py:189: FutureWarning: jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() instead as a drop-in replacement.\n",
            "  'instead as a drop-in replacement.', FutureWarning)\n",
            " 34%|███▍      | 34/100 [20:12<30:29, 27.72s/it]"
          ]
        }
      ],
      "source": [
        "TRAIN_STEPS = 100\n",
        "maml_losses = []\n",
        "for i in tqdm(range(TRAIN_STEPS)):\n",
        "    # get x_support, y_support, x_query, y_query batch\n",
        "    x_support_batch = []\n",
        "    y_support_batch = []\n",
        "    x_query_batch = []\n",
        "    y_query_batch = []\n",
        "    for j in range(batch_size):\n",
        "        support, query = train_dataset.get_mini_dataset()\n",
        "        x_support, y_support = support['images'], support['labels']\n",
        "        x_query, y_query = query['images'], query['labels']\n",
        "        x_support_batch.append(x_support)\n",
        "        y_support_batch.append(y_support)\n",
        "        x_query_batch.append(x_query)\n",
        "        y_query_batch.append(y_query)\n",
        "    x_support_batch = np.stack(x_support_batch)\n",
        "    y_support_batch = np.stack(y_support_batch)\n",
        "    x_query_batch = np.stack(x_query_batch)\n",
        "    y_query_batch = np.stack(y_query_batch)\n",
        "    opt_state, l = batch_step(i, opt_state, x_support_batch, y_support_batch, x_query_batch, y_query_batch)\n",
        "    maml_losses.append(l)\n",
        "\n",
        "net_params = get_params(opt_state)"
      ],
      "id": "e88d7be6-e143-492a-b05d-1908246d94d9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRWSx8dg7cvb"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(TRAIN_STEPS), np.array(maml_losses))\n",
        "maml_losses[-10:]"
      ],
      "id": "uRWSx8dg7cvb"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "maml-omniglot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}